
# MICROPROJECT 2.5: Train-Test Split and Data Preparation (Beginner)

**Course:** 316316 - Machine Learning  
**Unit:** 2 (Data Preparation)  
**Duration:** 1 week  
**Submission:** Jupyter Notebook (.ipynb) + CSV files + PDF Summary  
**Weight:** 8% of unit assessment

---

## ğŸ¯ Objective
Learn how to split a dataset into training and testing sets. Understand why this is crucial for building reliable ML models.

---

## ğŸ“‹ Requirements

### Task 1: Load and Prepare Data
- Use pandas to load a small dataset (e.g., Iris, Titanic, or any CSV)
- Clean the data (remove duplicates, handle missing values)

### Task 2: Train-Test Split
- Use Scikit-learn's train_test_split to split the data (e.g., 80% train, 20% test)
- Show the number of samples in each set
- Explain why splitting is important in a markdown cell

### Task 3: Save Split Data
- Save the train and test sets as separate CSV files

---

## ğŸ“¤ Deliverables
- Jupyter Notebook with code and markdown explanations
- Train and test CSV files
- Short PDF summary (1 page) describing your process

---

## ğŸ“ Tips for Beginners
- Focus on simple, clear steps
- Use comments to explain your code
- Ask for help if you're unsure about any step
- **Sections:** Baseline â†’ Feature engineering â†’ Enhanced model â†’ Comparison

### 2. Feature Engineering Report (20% weight)
- **File:** `MP2_4_Group[ID]_Report.pdf`
- **Content:** Feature creation/selection process, impact analysis

### 3. Visualizations (15% weight)
- **File:** `MP2_4_Group[ID]_Visualizations.pdf`
- **Content:** Feature importances, before/after comparisons

### 4. Presentation (15% weight)
- **File:** `MP2_4_Group[ID]_Presentation.pdf`
- **Content:** 6-8 slides on methodology and results

---

## ğŸ“Š Group Evaluation Rubric

| Criteria | Excellent (5) | Good (4) | Satisfactory (3) | Poor (1-2) |
|----------|---------------|----------|------------------|------------|
| **Feature Creation** | Multiple, relevant, creative | Good features | Basic features | Few/irrelevant |
| **Feature Transformation** | Proper scaling/encoding | Good transformation | Basic | Poor/none |
| **Feature Selection** | Robust, justified | Good selection | Basic | Poor/none |
| **Model Performance** | Significant improvement | Good improvement | Minor | No improvement |
| **Visualization** | Excellent plots, clear impact | Good plots | Basic plots | Poor quality |
| **Report Quality** | Clear analysis, insights | Good analysis | Basic summary | Poor docs |
| **Presentation** | Clear, engaging slides | Good slides | Basic presentation | Poor slides |
| **Collaboration** | Excellent teamwork | Good coordination | Basic collaboration | Poor teamwork |

**Total:** /40 per group

---

## ğŸ“ Template Code

```python

# MICROPROJECT 3.2: Feature Extraction with PCA (Beginner)

**Course:** 316316 - Machine Learning  
**Unit:** 3 (Feature Selection)  
**Group Size:** 3 students  
**Duration:** 1 week  
**Weight:** 8% of course assessment

---

## ğŸ¯ Objective
Learn how to use Principal Component Analysis (PCA) to extract important features and reduce dimensionality in a dataset.

---

## ğŸ“‹ Requirements

### Task 1: Load a Dataset
- Use pandas to load a small dataset (e.g., Iris, Wine, or any CSV)

### Task 2: Apply PCA
- Use Scikit-learn to perform PCA on the dataset
- Show how many components explain most of the variance
- Visualize the first two principal components in a scatter plot

### Task 3: Explain PCA
- Write a markdown cell explaining what PCA does and why itâ€™s useful

---

## ğŸ“¤ Deliverables
- Jupyter Notebook with code and markdown explanations
- Short PDF summary (1 page) describing your process

---

## ğŸ“ Tips for Beginners
- Focus on simple, clear steps
- Use comments to explain your code
- Ask for help if youâ€™re unsure about any step

**Deadline:** [Date]