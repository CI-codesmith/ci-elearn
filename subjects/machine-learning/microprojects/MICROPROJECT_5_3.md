
# MICROPROJECT 5.3: Ethics in Practice

**Course:** 316316 - Machine Learning  
**Unit:** 5 (Ethics, Production & Applications)  
**Group Size:** 3 students  
**Duration:** 1.5 weeks  
**Weight:** 10% of course assessment

---

## üë• Group Roles
- **Data Engineer:** Data analysis and bias detection
- **ML Engineer:** Fairness metric implementation
- **Analyst:** Case study analysis and reporting

---

## üéØ Objective
Analyze real-world case studies of machine learning ethics, focusing on bias, fairness, and responsible AI. Apply fairness metrics to a dataset and propose mitigation strategies.

---

## üìã Requirements

### Case Study Selection
Choose **one** real-world case:
- **COMPAS Recidivism** (criminal justice bias)
- **Gender Shades** (facial recognition bias)
- **Credit Scoring** (financial fairness)

### Technical Requirements
- Analyze dataset for bias and fairness
- Implement fairness metrics (demographic parity, equal opportunity, disparate impact)
- Visualize and interpret fairness results
- Propose and test mitigation strategies (reweighting, preprocessing, etc.)

### Model Requirements
1. **Data Analysis** (explore, visualize bias)
2. **Fairness Metrics** (compute, interpret)
3. **Mitigation** (apply, evaluate)
4. **Case Study Report** (analysis, recommendations)

---

## üì§ Group Deliverables

### 1. Jupyter Notebook (40% weight)
- **File:** `MP5_3_Group[ID]_Ethics.ipynb`
- **Sections:** Data analysis ‚Üí Fairness metrics ‚Üí Mitigation ‚Üí Case study

### 2. Case Study Report (30% weight)
- **File:** `MP5_3_Group[ID]_Report.pdf`
- **Content:** Case analysis, findings, recommendations

### 3. Visualizations (20% weight)
- **File:** `MP5_3_Group[ID]_Visualizations.pdf`
- **Content:** Bias/fairness plots, before/after mitigation

### 4. Presentation (10% weight)
- **File:** `MP5_3_Group[ID]_Presentation.pdf`
- **Content:** 5-7 slides on ethical issues and solutions

---

## üìä Group Evaluation Rubric

| Criteria | Excellent (5) | Good (4) | Satisfactory (3) | Poor (1-2) |
|----------|---------------|----------|------------------|------------|
| **Bias Analysis** | Comprehensive, insightful | Good analysis | Basic | Poor/none |
| **Fairness Metrics** | Correct, multiple metrics | Good metrics | Basic | Poor/none |
| **Mitigation** | Effective, justified | Good mitigation | Basic | Poor/none |
| **Visualization** | Clear, insightful, before/after | Good plots | Basic plots | Poor quality |
| **Report Quality** | Clear analysis, insights | Good analysis | Basic summary | Poor docs |
| **Presentation** | Clear, engaging slides | Good slides | Basic presentation | Poor slides |
| **Collaboration** | Excellent teamwork | Good coordination | Basic collaboration | Poor teamwork |

**Total:** /35 per group

---

## üìù Template Code

```python
# MICROPROJECT 5.3: Ethics in Practice
# Group: [ID]
# Case Study: [Chosen]

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# from aif360 or fairlearn import metrics (optional)

# 1. DATA LOADING
# df = pd.read_csv('your_dataset.csv')

# 2. BIAS ANALYSIS
# ...

# 3. FAIRNESS METRICS
# ...

# 4. MITIGATION
# ...

# 5. VISUALIZATION
# ...
```

---

## üÜò Resources
- Fairness/fairlearn/aif360 guides
- Real-world case study documentation
- Course practicals 15 reference

**Deadline:** [Date]