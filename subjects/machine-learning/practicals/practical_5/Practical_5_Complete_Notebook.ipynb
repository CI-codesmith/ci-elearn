{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f27099",
   "metadata": {},
   "source": [
    "## Student Information\n",
    "\n",
    "**Name:** [Your Name Here]  \n",
    "**Roll Number:** [Your Roll Number]  \n",
    "**Date:** [Submission Date]  \n",
    "**College:** [Your College Name]  \n",
    "**Academic Year:** 2025-2026  \n",
    "\n",
    "---\n",
    "\n",
    "## Learning Outcomes Checklist\n",
    "\n",
    "- [ ] LO1: Understand linear regression theory\n",
    "- [ ] LO2: Implement Simple Linear Regression\n",
    "- [ ] LO3: Implement Multiple Linear Regression\n",
    "- [ ] LO4: Analyze regression coefficients\n",
    "- [ ] LO5: Calculate evaluation metrics (MSE, RMSE, MAE, R¬≤)\n",
    "- [ ] LO6: Perform residual analysis\n",
    "- [ ] LO7: Detect overfitting/underfitting\n",
    "- [ ] LO8: Apply feature scaling\n",
    "- [ ] LO9: Visualize regression results\n",
    "- [ ] LO10: Compare simple vs multiple regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a1584",
   "metadata": {},
   "source": [
    "## Phase 0: Environment Setup & Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c39b981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (mean_squared_error, mean_absolute_error, r2_score)\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Print versions\n",
    "print(\"üìö LIBRARY VERSIONS:\")\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Scikit-learn: {__import__('sklearn').__version__}\")\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21362f5e",
   "metadata": {},
   "source": [
    "## Phase 1: Dataset Creation & Exploration\n",
    "\n",
    "Create a regression dataset for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c864f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regression dataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "print(\"üìä CREATING REGRESSION DATASET:\\n\")\n",
    "\n",
    "# Load Diabetes dataset\n",
    "X, y = load_diabetes(return_X_y=True)\n",
    "feature_names = load_diabetes().feature_names\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['Target'] = y\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {list(feature_names)[:5]}... (10 total)\")\n",
    "print(f\"Target: Diabetes disease progression\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset statistics:\")\n",
    "print(df[['age', 'sex', 'bmi', 'Target']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd232e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration\n",
    "print(\"üìà DATA EXPLORATION:\\n\")\n",
    "\n",
    "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"\\nTarget variable statistics:\")\n",
    "print(f\"Mean: {df['Target'].mean():.2f}\")\n",
    "print(f\"Std: {df['Target'].std():.2f}\")\n",
    "print(f\"Min: {df['Target'].min():.2f}\")\n",
    "print(f\"Max: {df['Target'].max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a397690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize target distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(df['Target'], bins=30, color='steelblue', edgecolor='black')\n",
    "axes[0].set_xlabel('Target Value')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Target Distribution')\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['Target'])\n",
    "axes[1].set_ylabel('Target Value')\n",
    "axes[1].set_title('Target Box Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Target distribution visualized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ccdee3",
   "metadata": {},
   "source": [
    "## Phase 2: Correlation Analysis\n",
    "\n",
    "Analyze relationships between features and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fb560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations\n",
    "print(\"üìä CORRELATION ANALYSIS:\\n\")\n",
    "\n",
    "correlation_with_target = df.corr()['Target'].sort_values(ascending=False)\n",
    "print(\"Correlation with Target (Top 10):\")\n",
    "print(correlation_with_target.head(10))\n",
    "\n",
    "# Visualize correlations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot of correlations\n",
    "top_features = correlation_with_target[1:6]  # Exclude Target itself\n",
    "axes[0].barh(range(len(top_features)), top_features.values)\n",
    "axes[0].set_yticks(range(len(top_features)))\n",
    "axes[0].set_yticklabels(top_features.index)\n",
    "axes[0].set_xlabel('Correlation Coefficient')\n",
    "axes[0].set_title('Top 5 Features by Correlation')\n",
    "\n",
    "# Scatter plot: BMI vs Target\n",
    "axes[1].scatter(df['bmi'], df['Target'], alpha=0.5)\n",
    "axes[1].set_xlabel('BMI')\n",
    "axes[1].set_ylabel('Target')\n",
    "axes[1].set_title('BMI vs Target (Strongest Correlation)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Correlation analysis completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d2063",
   "metadata": {},
   "source": [
    "## Phase 3: Data Preparation & Train-Test Split\n",
    "\n",
    "Prepare data for regression model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f33ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "print(\"üîÄ DATA PREPARATION:\\n\")\n",
    "\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n",
    "print(f\"\\n‚úÖ Data split successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7815c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling\n",
    "print(\"\\nüìè FEATURE SCALING:\\n\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Training data - Mean: {X_train_scaled.mean(axis=0):.4f}\")\n",
    "print(f\"Training data - Std: {X_train_scaled.std(axis=0):.4f}\")\n",
    "print(f\"\\n‚úÖ Features scaled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a6dd6",
   "metadata": {},
   "source": [
    "## Phase 4: Simple Linear Regression\n",
    "\n",
    "Implement regression with a single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ef7bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Linear Regression (using BMI only)\n",
    "print(\"üìà SIMPLE LINEAR REGRESSION:\\n\")\n",
    "\n",
    "X_train_simple = X_train[['bmi']].values\n",
    "X_test_simple = X_test[['bmi']].values\n",
    "\n",
    "# Scale the feature\n",
    "scaler_simple = StandardScaler()\n",
    "X_train_simple_scaled = scaler_simple.fit_transform(X_train_simple)\n",
    "X_test_simple_scaled = scaler_simple.transform(X_test_simple)\n",
    "\n",
    "# Train simple model\n",
    "simple_model = LinearRegression()\n",
    "simple_model.fit(X_train_simple_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_simple = simple_model.predict(X_test_simple_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "simple_mse = mean_squared_error(y_test, y_pred_simple)\n",
    "simple_rmse = np.sqrt(simple_mse)\n",
    "simple_mae = mean_absolute_error(y_test, y_pred_simple)\n",
    "simple_r2 = r2_score(y_test, y_pred_simple)\n",
    "\n",
    "print(f\"Simple Linear Regression Results:\")\n",
    "print(f\"Coefficient (slope): {simple_model.coef_[0]:.4f}\")\n",
    "print(f\"Intercept (bias): {simple_model.intercept_:.4f}\")\n",
    "print(f\"Equation: y = {simple_model.coef_[0]:.4f} * x + {simple_model.intercept_:.4f}\")\n",
    "print(f\"\\nMetrics:\")\n",
    "print(f\"  MSE: {simple_mse:.4f}\")\n",
    "print(f\"  RMSE: {simple_rmse:.4f}\")\n",
    "print(f\"  MAE: {simple_mae:.4f}\")\n",
    "print(f\"  R¬≤ Score: {simple_r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe518ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Simple Linear Regression\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Scatter plot with regression line\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_test_simple, y_test, alpha=0.6, label='Actual')\n",
    "plt.scatter(X_test_simple, y_pred_simple, alpha=0.6, color='red', label='Predicted')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Target')\n",
    "plt.title('Simple Linear Regression: BMI vs Target')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals plot\n",
    "residuals_simple = y_test - y_pred_simple\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_pred_simple, residuals_simple, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residuals Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Simple regression visualization completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb53d38e",
   "metadata": {},
   "source": [
    "## Phase 5: Multiple Linear Regression\n",
    "\n",
    "Implement regression using all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0922e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Linear Regression (using all features)\n",
    "print(\"üìà MULTIPLE LINEAR REGRESSION:\\n\")\n",
    "\n",
    "# Train model on scaled data\n",
    "multiple_model = LinearRegression()\n",
    "multiple_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = multiple_model.predict(X_train_scaled)\n",
    "y_pred_test = multiple_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics\n",
    "mse_train = mean_squared_error(y_train, y_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\"Multiple Linear Regression Results:\")\n",
    "print(f\"\\nTraining Metrics:\")\n",
    "print(f\"  MSE: {mse_train:.4f}\")\n",
    "print(f\"  R¬≤ Score: {r2_train:.4f}\")\n",
    "print(f\"\\nTesting Metrics:\")\n",
    "print(f\"  MSE: {mse_test:.4f}\")\n",
    "print(f\"  RMSE: {rmse_test:.4f}\")\n",
    "print(f\"  MAE: {mae_test:.4f}\")\n",
    "print(f\"  R¬≤ Score: {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb52a6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (coefficients)\n",
    "print(\"\\nüìä FEATURE IMPORTANCE (COEFFICIENTS):\\n\")\n",
    "\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Coefficient': multiple_model.coef_\n",
    "}).sort_values('Coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(coefficients.to_string(index=False))\n",
    "print(f\"\\nIntercept: {multiple_model.intercept_:.4f}\")\n",
    "\n",
    "# Visualize coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['green' if x > 0 else 'red' for x in coefficients['Coefficient']]\n",
    "plt.barh(coefficients['Feature'], coefficients['Coefficient'], color=colors)\n",
    "plt.xlabel('Coefficient Value')\n",
    "plt.title('Feature Coefficients - Multiple Linear Regression')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Feature importance visualized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e5f5ea",
   "metadata": {},
   "source": [
    "## Phase 6: Residual Analysis\n",
    "\n",
    "Analyze residuals for model diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bad2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "print(\"üîç RESIDUAL ANALYSIS:\\n\")\n",
    "\n",
    "residuals = y_test - y_pred_test\n",
    "\n",
    "print(f\"Residuals Statistics:\")\n",
    "print(f\"  Mean: {residuals.mean():.6f}\")\n",
    "print(f\"  Std Dev: {residuals.std():.4f}\")\n",
    "print(f\"  Min: {residuals.min():.4f}\")\n",
    "print(f\"  Max: {residuals.max():.4f}\")\n",
    "print(f\"\\nNormality Test (Shapiro-Wilk):\")\n",
    "stat, p_value = stats.shapiro(residuals)\n",
    "print(f\"  p-value: {p_value:.6f}\")\n",
    "print(f\"  Normal distribution: {'Yes' if p_value > 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55953a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize residuals\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Residuals vs Predicted\n",
    "axes[0, 0].scatter(y_pred_test, residuals, alpha=0.6)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 0].set_xlabel('Predicted Values')\n",
    "axes[0, 0].set_ylabel('Residuals')\n",
    "axes[0, 0].set_title('Residuals vs Predicted Values')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram of residuals\n",
    "axes[0, 1].hist(residuals, bins=20, edgecolor='black')\n",
    "axes[0, 1].set_xlabel('Residuals')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].set_title('Residuals Distribution')\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Actual vs Predicted\n",
    "axes[1, 1].scatter(y_test, y_pred_test, alpha=0.6)\n",
    "axes[1, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "axes[1, 1].set_xlabel('Actual Values')\n",
    "axes[1, 1].set_ylabel('Predicted Values')\n",
    "axes[1, 1].set_title('Actual vs Predicted')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Residual diagnostics visualized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bb9b02",
   "metadata": {},
   "source": [
    "## Phase 7: Model Comparison\n",
    "\n",
    "Compare Simple vs Multiple Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5506439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison\n",
    "print(\"üìä MODEL COMPARISON:\\n\")\n",
    "\n",
    "comparison_data = [\n",
    "    {\n",
    "        'Model': 'Simple Linear Regression',\n",
    "        'Features': 1,\n",
    "        'MSE': simple_mse,\n",
    "        'RMSE': simple_rmse,\n",
    "        'MAE': simple_mae,\n",
    "        'R¬≤ Score': simple_r2\n",
    "    },\n",
    "    {\n",
    "        'Model': 'Multiple Linear Regression',\n",
    "        'Features': X_train.shape[1],\n",
    "        'MSE': mse_test,\n",
    "        'RMSE': rmse_test,\n",
    "        'MAE': mae_test,\n",
    "        'R¬≤ Score': r2_test\n",
    "    }\n",
    "]\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\nImprovement:\")\n",
    "print(f\"  R¬≤ improvement: {(r2_test - simple_r2)*100:.2f}%\")\n",
    "print(f\"  RMSE reduction: {(simple_rmse - rmse_test)*100/simple_rmse:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6799701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "models = ['Simple', 'Multiple']\n",
    "rmse_values = [simple_rmse, rmse_test]\n",
    "r2_values = [simple_r2, r2_test]\n",
    "\n",
    "# RMSE comparison\n",
    "axes[0].bar(models, rmse_values, color=['orange', 'green'])\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].set_title('Root Mean Squared Error Comparison')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# R¬≤ comparison\n",
    "axes[1].bar(models, r2_values, color=['orange', 'green'])\n",
    "axes[1].set_ylabel('R¬≤ Score')\n",
    "axes[1].set_title('R¬≤ Score Comparison')\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Model comparison visualized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7fd7eb",
   "metadata": {},
   "source": [
    "## Phase 8: Overfitting/Underfitting Analysis\n",
    "\n",
    "Detect and analyze overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ebeff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overfitting/underfitting\n",
    "print(\"üîç OVERFITTING/UNDERFITTING ANALYSIS:\\n\")\n",
    "\n",
    "train_r2 = r2_score(y_train, y_pred_train)\n",
    "test_r2 = r2_test\n",
    "\n",
    "print(f\"Training R¬≤ Score: {train_r2:.4f}\")\n",
    "print(f\"Testing R¬≤ Score: {test_r2:.4f}\")\n",
    "print(f\"Difference: {train_r2 - test_r2:.4f}\")\n",
    "\n",
    "if abs(train_r2 - test_r2) < 0.05:\n",
    "    status = \"‚úÖ Good fit (minimal overfitting)\"\n",
    "elif train_r2 - test_r2 > 0.1:\n",
    "    status = \"‚ö†Ô∏è Overfitting detected (high training accuracy, lower test accuracy)\"\n",
    "elif test_r2 < 0.5:\n",
    "    status = \"‚ö†Ô∏è Underfitting detected (both training and test accuracy are low)\"\n",
    "else:\n",
    "    status = \"‚úÖ Acceptable fit\"\n",
    "\n",
    "print(f\"\\nModel Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbf6462",
   "metadata": {},
   "source": [
    "## Phase 9: Practical Tests\n",
    "\n",
    "Complete all 5 tests to verify your learning outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec14eff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 1: DATA PREPARATION\n",
    "print(\"üß™ TEST 1: DATA PREPARATION\")\n",
    "try:\n",
    "    assert X_train.shape[0] > 0, \"Training set is empty!\"\n",
    "    assert X_test.shape[0] > 0, \"Test set is empty!\"\n",
    "    assert X_train.shape[1] == X_test.shape[1], \"Feature mismatch!\"\n",
    "    assert len(y_train) == X_train.shape[0], \"Target mismatch!\"\n",
    "    print(f\"‚úÖ TEST 1 PASSED: Train {X_train.shape[0]}, Test {X_test.shape[0]}\")\n",
    "    test1_result = \"PASSED\"\n",
    "except AssertionError as e:\n",
    "    print(f\"‚ùå TEST 1 FAILED: {e}\")\n",
    "    test1_result = \"FAILED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6748f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 2: SIMPLE LINEAR REGRESSION\n",
    "print(\"\\nüß™ TEST 2: SIMPLE LINEAR REGRESSION\")\n",
    "try:\n",
    "    assert simple_r2 > 0.3, \"Simple model R¬≤ too low!\"\n",
    "    assert len(y_pred_simple) == len(y_test), \"Prediction size mismatch!\"\n",
    "    assert not np.isnan(simple_model.coef_[0]), \"Coefficient is NaN!\"\n",
    "    print(f\"‚úÖ TEST 2 PASSED: R¬≤ = {simple_r2:.4f}\")\n",
    "    test2_result = \"PASSED\"\n",
    "except AssertionError as e:\n",
    "    print(f\"‚ùå TEST 2 FAILED: {e}\")\n",
    "    test2_result = \"FAILED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c10078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 3: MULTIPLE LINEAR REGRESSION\n",
    "print(\"\\nüß™ TEST 3: MULTIPLE LINEAR REGRESSION\")\n",
    "try:\n",
    "    assert r2_test > simple_r2, \"Multiple model should outperform simple!\"\n",
    "    assert len(multiple_model.coef_) == X_train.shape[1], \"Coefficient count mismatch!\"\n",
    "    assert r2_test > 0.4, \"Model R¬≤ too low!\"\n",
    "    print(f\"‚úÖ TEST 3 PASSED: R¬≤ = {r2_test:.4f}\")\n",
    "    test3_result = \"PASSED\"\n",
    "except AssertionError as e:\n",
    "    print(f\"‚ùå TEST 3 FAILED: {e}\")\n",
    "    test3_result = \"FAILED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af72a60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 4: METRICS CALCULATION\n",
    "print(\"\\nüß™ TEST 4: METRICS CALCULATION\")\n",
    "try:\n",
    "    assert not np.isnan(mse_test), \"MSE is NaN!\"\n",
    "    assert not np.isnan(rmse_test), \"RMSE is NaN!\"\n",
    "    assert not np.isnan(mae_test), \"MAE is NaN!\"\n",
    "    assert 0 <= r2_test <= 1, \"R¬≤ out of range!\"\n",
    "    assert rmse_test > 0, \"RMSE should be positive!\"\n",
    "    print(f\"‚úÖ TEST 4 PASSED: All metrics valid\")\n",
    "    test4_result = \"PASSED\"\n",
    "except AssertionError as e:\n",
    "    print(f\"‚ùå TEST 4 FAILED: {e}\")\n",
    "    test4_result = \"FAILED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3954714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 5: RESIDUAL ANALYSIS\n",
    "print(\"\\nüß™ TEST 5: RESIDUAL ANALYSIS\")\n",
    "try:\n",
    "    residuals_test = y_test - y_pred_test\n",
    "    assert abs(residuals_test.mean()) < 1, \"Residuals should be centered near zero!\"\n",
    "    assert residuals_test.std() > 0, \"Residuals should have variance!\"\n",
    "    assert len(residuals_test) == len(y_test), \"Residuals length mismatch!\"\n",
    "    print(f\"‚úÖ TEST 5 PASSED: Residuals analyzed\")\n",
    "    test5_result = \"PASSED\"\n",
    "except AssertionError as e:\n",
    "    print(f\"‚ùå TEST 5 FAILED: {e}\")\n",
    "    test5_result = \"FAILED\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee9c1fb",
   "metadata": {},
   "source": [
    "## Results Summary\n",
    "\n",
    "### Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644604d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary report\n",
    "test_summary = pd.DataFrame([\n",
    "    {'Test': 'Test 1: Data Preparation', 'Result': test1_result},\n",
    "    {'Test': 'Test 2: Simple Linear Regression', 'Result': test2_result},\n",
    "    {'Test': 'Test 3: Multiple Linear Regression', 'Result': test3_result},\n",
    "    {'Test': 'Test 4: Metrics Calculation', 'Result': test4_result},\n",
    "    {'Test': 'Test 5: Residual Analysis', 'Result': test5_result}\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TEST RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(test_summary.to_string(index=False))\n",
    "\n",
    "passed = sum([1 for r in [test1_result, test2_result, test3_result, test4_result, test5_result] if r == 'PASSED'])\n",
    "total = 5\n",
    "print(f\"\\nüìä SCORE: {passed}/{total} TESTS PASSED ({passed*100/total:.0f}%)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf686d8a",
   "metadata": {},
   "source": [
    "## Reflections & Learnings\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "1. **Simple vs Multiple Regression:**\n",
    "   - Simple regression is interpretable but limited\n",
    "   - Multiple regression captures complex relationships\n",
    "   - More features don't always mean better model\n",
    "\n",
    "2. **Feature Coefficients:**\n",
    "   - Positive coefficients increase predictions\n",
    "   - Negative coefficients decrease predictions\n",
    "   - Magnitude indicates strength of relationship\n",
    "\n",
    "3. **Residual Analysis:**\n",
    "   - Residuals should be normally distributed\n",
    "   - Residuals should have mean near zero\n",
    "   - Patterns in residuals indicate model issues\n",
    "\n",
    "4. **Evaluation Metrics:**\n",
    "   - R¬≤ tells proportion of variance explained\n",
    "   - RMSE in same units as target (interpretable)\n",
    "   - MAE is robust to outliers\n",
    "\n",
    "5. **Overfitting/Underfitting:**\n",
    "   - Gap between train and test performance indicates overfitting\n",
    "   - Low performance on both indicates underfitting\n",
    "   - Feature scaling is crucial for fair comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f32b6a8",
   "metadata": {},
   "source": [
    "## Submission Checklist\n",
    "\n",
    "Before submitting your practical, verify:\n",
    "\n",
    "### Code Completion\n",
    "- [ ] Phase 1 (Data Exploration): Completed with visualizations\n",
    "- [ ] Phase 2 (Correlation): Correlation analysis done\n",
    "- [ ] Phase 3 (Data Prep): Train-test split with scaling\n",
    "- [ ] Phase 4 (Simple): Simple regression implemented\n",
    "- [ ] Phase 5 (Multiple): Multiple regression implemented\n",
    "- [ ] Phase 6 (Residuals): Residual analysis completed\n",
    "- [ ] Phase 7 (Comparison): Models compared\n",
    "- [ ] Phase 8 (Fit Check): Overfitting analysis done\n",
    "\n",
    "### Test Results\n",
    "- [ ] All 5 tests passed ‚úÖ\n",
    "- [ ] Test output clearly visible\n",
    "- [ ] Error handling demonstrated\n",
    "- [ ] Performance metrics recorded\n",
    "\n",
    "### Documentation\n",
    "- [ ] Student information filled\n",
    "- [ ] Learning outcomes checklist marked\n",
    "- [ ] Reflections written\n",
    "- [ ] Code is well-commented\n",
    "- [ ] All output is visible and clear\n",
    "\n",
    "### Files\n",
    "- [ ] Notebook saved as `Practical_5_Complete_Notebook.ipynb`\n",
    "- [ ] PDF exported from notebook\n",
    "- [ ] No errors in notebook execution\n",
    "\n",
    "---\n",
    "\n",
    "**Practical Status:** Ready for submission ‚úÖ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
