# PRACTICAL 9: Feature Extraction and Transformation

## Course Information
- **Course Code:** 316316
- **Course Title:** Machine Learning
- **Semester:** 6th
- **Practical Duration:** 2 Hours
- **Learning Outcome Code:** LLO 9.1
- **Aligned Course Outcomes:** CO1, CO3

---

## Learning Outcomes (Practical Level)

After completing this practical, students will be able to:

1. **Extract meaningful features** from raw data
2. **Apply transformation techniques** to data
3. **Handle different data types** (numerical, categorical, text)
4. **Create feature pipelines** for automated workflows
5. **Improve model performance** through feature engineering

---

## Practical Objective

This practical teaches feature engineering and transformation techniques essential for ML. Students will learn:
- Feature extraction from raw data
- Polynomial and interaction features
- Text feature extraction (TF-IDF, Word2Vec)
- Image feature extraction
- Pipeline creation for reproducibility

---

## Prerequisites

- Completion of Practicals 1-8
- Understanding of data preprocessing
- Knowledge of feature scaling

---

## Topics Covered

1. **Numerical Feature Transformation**
   - Polynomial features
   - Interaction features
   - Binning and discretization
   - Mathematical transformations (log, sqrt, etc.)

2. **Categorical Feature Extraction**
   - One-hot encoding
   - Label encoding
   - Ordinal encoding
   - Frequency encoding
   - Target encoding

3. **Text Feature Extraction**
   - Tokenization
   - TF-IDF (Term Frequency-Inverse Document Frequency)
   - Count Vectorizer
   - Word embeddings (Word2Vec, GloVe)
   - Bag of Words

4. **Date/Time Features**
   - Extracting year, month, day, hour
   - Day of week and cyclical features
   - Creating lag features
   - Rolling statistics

5. **Domain-Specific Features**
   - Business logic-based features
   - Aggregations and groupby operations
   - Ratio features
   - Statistical features

6. **Feature Pipelines**
   - Creating sklearn pipelines
   - Combining preprocessors and models
   - Feature transformers composition
   - Custom transformers

7. **Feature Scaling and Normalization**
   - StandardScaler, MinMaxScaler
   - RobustScaler, QuantileTransformer
   - PowerTransformer

---

## Learning Resources

- **Libraries:** Scikit-learn, TextBlob, spaCy, NLTK
- **Datasets:** Text data, time series, mixed types
- **Tools:** Pipeline, ColumnTransformer

---

## Assessment Criteria

- Appropriate feature extraction
- Correct transformation implementation
- Pipeline construction
- Feature quality improvement
- Model performance enhancement
- Code documentation

---

## Next Steps

After completing this practical:
- Move to Practical 10: Ensemble learning methods
- Work on feature engineering competitions
- Explore advanced NLP techniques
