{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc48c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff80a012",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(f\"Data shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f832c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_scores = cross_val_score(rf, X, y, cv=5)\n",
    "print(f\"Random Forest CV scores: {rf_scores}\")\n",
    "print(f\"Mean: {rf_scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d92d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "gb_scores = cross_val_score(gb, X, y, cv=5)\n",
    "print(f\"Gradient Boosting CV scores: {gb_scores}\")\n",
    "print(f\"Mean: {gb_scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53af2df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "ada = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "ada_scores = cross_val_score(ada, X, y, cv=5)\n",
    "print(f\"AdaBoost CV scores: {ada_scores}\")\n",
    "print(f\"Mean: {ada_scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3db350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "rf.fit(X, y)\n",
    "importances = rf.feature_importances_\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.barh(iris.feature_names, importances)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b32fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting ensemble\n",
    "voting = VotingClassifier(\n",
    "    estimators=[('rf', RandomForestClassifier()), ('gb', GradientBoostingClassifier()), ('ada', AdaBoostClassifier())],\n",
    "    voting='soft'\n",
    ")\n",
    "voting_scores = cross_val_score(voting, X, y, cv=5)\n",
    "print(f\"Voting Ensemble scores: {voting_scores}\")\n",
    "print(f\"Mean: {voting_scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90ec397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison\n",
    "models = {'Random Forest': rf_scores, 'Gradient Boosting': gb_scores, 'AdaBoost': ada_scores, 'Voting': voting_scores}\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.boxplot(models.values(), labels=models.keys())\n",
    "plt.ylabel('CV Score')\n",
    "plt.title('Ensemble Methods Comparison')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06c147b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []\n",
    "test1 = rf_scores.mean() > 0.9\n",
    "test_results.append((\"Test 1: RF high accuracy\", test1))\n",
    "test2 = gb_scores.mean() > 0.9\n",
    "test_results.append((\"Test 2: GB high accuracy\", test2))\n",
    "test3 = ada_scores.mean() > 0.7\n",
    "test_results.append((\"Test 3: AdaBoost decent accuracy\", test3))\n",
    "test4 = voting_scores.mean() > 0.9\n",
    "test_results.append((\"Test 4: Voting ensemble good\", test4))\n",
    "test5 = len(importances) == 4\n",
    "test_results.append((\"Test 5: Feature importances correct\", test5))\n",
    "passed = sum(1 for _, r in test_results if r)\n",
    "print(f\"\\nPASSED: {passed}/{len(test_results)}\")\n",
    "for name, result in test_results:\n",
    "    print(f\"{'✅' if result else '❌'} {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1a701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PRACTICAL 10 COMPLETE\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
