# Practical 8: Model Evaluation & Selection - Complete Guide

## Learning Objectives
1. K-fold cross-validation
2. Grid search for hyperparameters
3. Evaluation metrics comparison
4. Model selection strategies
5. Learning curves analysis
6. Overfitting detection
7. Cross-validation scoring
8. Hyperparameter ranges
9. Computational efficiency
10. Best practices in model selection

## Key Concepts

### Cross-Validation
Splits data into k folds, trains on k-1, tests on 1. Prevents overfitting.

### Grid Search
Tests all combinations of hyperparameters, returns best ones.

### Metrics
- Regression: MSE, MAE, RÂ², RMSE
- Classification: Accuracy, Precision, Recall, F1

### Learning Curves
Show train/test accuracy vs training size. Diagnose bias/variance.

---
See Practical_8_Complete_Notebook.ipynb for full implementation.
